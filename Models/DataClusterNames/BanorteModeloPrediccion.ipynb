{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa la libreria csv\n",
    "import csv\n",
    "\n",
    "# Se abre el archivo de texto, datos_generales.txt y se lee con el delimitador | \n",
    "with open('datos_generales.txt', 'r') as txtfile:\n",
    "    txtreader = csv.reader(txtfile, delimiter='|')\n",
    "\n",
    "    with open('datos_ofuscados.csv', 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        for row in txtreader:\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEC_CONS</th>\n",
       "      <th>FEC_PROC</th>\n",
       "      <th>TIP_TRAN</th>\n",
       "      <th>IMP_ORI_TOT</th>\n",
       "      <th>MON_IMP</th>\n",
       "      <th>IMP_DES</th>\n",
       "      <th>PAR_DES</th>\n",
       "      <th>CVE_COM</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NOM_COM</th>\n",
       "      <th>plasticoF</th>\n",
       "      <th>ClienteF</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28FEB2021:00:00:00.000000</td>\n",
       "      <td>01MAR2021</td>\n",
       "      <td>1</td>\n",
       "      <td>409.57</td>\n",
       "      <td>484</td>\n",
       "      <td>409.57</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1008440</td>\n",
       "      <td>5411</td>\n",
       "      <td>SORIANA343 GARZA SADA</td>\n",
       "      <td>F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...</td>\n",
       "      <td>0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...</td>\n",
       "      <td>TDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01MAR2021:00:00:00.000000</td>\n",
       "      <td>02MAR2021</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>484</td>\n",
       "      <td>17.00</td>\n",
       "      <td>20.6123</td>\n",
       "      <td>10025426</td>\n",
       "      <td>5815</td>\n",
       "      <td>APPLE.COM/BILL</td>\n",
       "      <td>F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...</td>\n",
       "      <td>0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...</td>\n",
       "      <td>TDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02MAR2021:00:00:00.000000</td>\n",
       "      <td>04MAR2021</td>\n",
       "      <td>1</td>\n",
       "      <td>69.00</td>\n",
       "      <td>484</td>\n",
       "      <td>69.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6041503</td>\n",
       "      <td>5499</td>\n",
       "      <td>7 ELEVEN HILARIO MTZ</td>\n",
       "      <td>F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...</td>\n",
       "      <td>0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...</td>\n",
       "      <td>TDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02MAR2021:20:15:02.000000</td>\n",
       "      <td>02MAR2021</td>\n",
       "      <td>1</td>\n",
       "      <td>998.37</td>\n",
       "      <td>484</td>\n",
       "      <td>998.37</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7895432</td>\n",
       "      <td>5411</td>\n",
       "      <td>MERCO NUEVO REPUBLO</td>\n",
       "      <td>F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...</td>\n",
       "      <td>0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...</td>\n",
       "      <td>TDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03MAR2021:00:00:00.000000</td>\n",
       "      <td>04MAR2021</td>\n",
       "      <td>1</td>\n",
       "      <td>259.00</td>\n",
       "      <td>484</td>\n",
       "      <td>259.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7948490</td>\n",
       "      <td>5499</td>\n",
       "      <td>7 ELEVEN PALESTINA</td>\n",
       "      <td>F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...</td>\n",
       "      <td>0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...</td>\n",
       "      <td>TDD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    FEC_CONS   FEC_PROC  TIP_TRAN  IMP_ORI_TOT  MON_IMP  \\\n",
       "0  28FEB2021:00:00:00.000000  01MAR2021         1       409.57      484   \n",
       "1  01MAR2021:00:00:00.000000  02MAR2021         1        17.00      484   \n",
       "2  02MAR2021:00:00:00.000000  04MAR2021         1        69.00      484   \n",
       "3  02MAR2021:20:15:02.000000  02MAR2021         1       998.37      484   \n",
       "4  03MAR2021:00:00:00.000000  04MAR2021         1       259.00      484   \n",
       "\n",
       "   IMP_DES  PAR_DES   CVE_COM   MCC                NOM_COM  \\\n",
       "0   409.57   0.0000   1008440  5411  SORIANA343 GARZA SADA   \n",
       "1    17.00  20.6123  10025426  5815         APPLE.COM/BILL   \n",
       "2    69.00   0.0000   6041503  5499   7 ELEVEN HILARIO MTZ   \n",
       "3   998.37   0.0000   7895432  5411    MERCO NUEVO REPUBLO   \n",
       "4   259.00   0.0000   7948490  5499     7 ELEVEN PALESTINA   \n",
       "\n",
       "                                           plasticoF  \\\n",
       "0  F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...   \n",
       "1  F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...   \n",
       "2  F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...   \n",
       "3  F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...   \n",
       "4  F9B9D796848AF6B19CE60682F5632F0CF500CADF7190B6...   \n",
       "\n",
       "                                            ClienteF tipo  \n",
       "0  0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...  TDD  \n",
       "1  0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...  TDD  \n",
       "2  0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...  TDD  \n",
       "3  0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...  TDD  \n",
       "4  0007ADBB921C28F452E4A6AC20C1B42A0FC94613163048...  TDD  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa la libreria pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Se lee el archivo de texto, datos_ofuscados.csv y se almacena en un dataframe de pandas\n",
    "file_path = 'datos_ofuscados.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Se imprime el dataframe de pandas\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa la libreria string y re\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Se define la funcion preprocess_text que recibe un texto y lo convierte a minusculas, elimina los numeros, \n",
    "# elimina los signos de puntuacion y elimina los espacios en blanco al inicio y al final del texto \n",
    "def preprocess_text_advanced(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Se aplica la funcion preprocess_text al dataframe de pandas y se almacena en una nueva columna llamada NOM_COM_clean_advanced\n",
    "df.to_csv('datos_ofuscados_preprocessed.csv', index=False)\n",
    "df['NOM_COM_clean_advanced'] = df['NOM_COM'].apply(preprocess_text_advanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         NOM_COM       Category\n",
      "135               IZ  COMPRABIEN  Miscellaneous\n",
      "172            IZ  TECKEL MEXICO  Miscellaneous\n",
      "497                       SYSCOM  Miscellaneous\n",
      "600    2CO.COM*MOVAVI.COM 163815  Miscellaneous\n",
      "648            POINTMP*MESASLETY  Miscellaneous\n",
      "...                          ...            ...\n",
      "26166        LIB GONVILL GRA PZA  Miscellaneous\n",
      "26169     ZTL*DISTRIBUIDORAARCAC  Miscellaneous\n",
      "26190          UXIXC GUADALAJARA  Miscellaneous\n",
      "26200               QIN GALERIAS  Miscellaneous\n",
      "26201               QIN GALERIAS  Miscellaneous\n",
      "\n",
      "[2318 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Se crea el diccionario keywords_dict que contiene las categorias y las palabras clave que se usaran para clasificar los nombres de los comercios\n",
    "keywords_dict = {\n",
    "    'Comida': ['restaurant', 'fprohibido', 'tio poncho', 's s', 'th', 'meat', 'mochis', 'baguet', 'maria bonita', 'italia', 'nipon', 'fries', 'dazs', 'asturi', 'ramos', 'timon', 'fish', 'applebees', 'yog', 'pizz', 'vino', 'bowl', 'lobster', 'pozole', 'bake', 'pay', 'modelor', 'mirai', 'maris', 'palmit', 'siber', 'rocket', 'bbq', 'hooter', 'cow', 'gourmet', 'elote', 'salad', 'pesca', 'cof', 'dq', 'camaron', 'denny', 'beer', 'tabern', 'vegan', 'veget', 'grill', 'lunch', 'brunch', 'maiz', 'nestle', 'la mexicana', 'granos', 'froyo', 'churr', 'cinnab', 'cerve', 'chicken', 'chocola', 'almuerzo', 'cantina', 'bimbo', 'birri', 'bar', 'tak', 'aliment', 'gelato', 'cocina', 'food', 'nutrisa', 'sushi', 'maison', 'pf', 'parril', 'chil', 'botan', 'starbuck', 'sanborn', 'pan', 'bis', 'toks', 'crep', 'asad', 'cremer', 'tostada', 'comi', 'buffet', 'cabrito', 'lacteo', 'cafe', 'pastor', 'pizza',  'mcdonalds', 'buffalo',  '7 eleven',  '7eleven','busha', 'bucha', 'monch', 'pollo', 'sayu', 'muncher', 'oxxo', 'rappi', 'rest',  'carls', 'little', 'subway', 'kfc', 'coffee', 'tortas', 'church', 'dominos', 'sazon', 'sirloin', 'josephinos', 'pastel', 'mc', 'taco', 'dairy', 'taque', 'jac', 'patsel', 'bur',  'wing', 'alita', 'antoj', 'vips', 'spikes', 'dona', 'repost', 'helado', 'el chino', 'sirlon', 'frut', 'bueneros', 'dulce', 'nacho', 'cafe', 'caffe'],\n",
    "    'Transporte': ['uber', 'senda', 'transp', 'est', 'mobility', 'ado', 'taxi', 'bus', 'metro', 'didi rides', 'cabify', 'lyft', 'taxify', 'didimx'],\n",
    "    'Ropa': ['ropa', 'converse', 'fan town', 'impuls', 'shoe', 'flexi', 'secret', 'vertiche', 'puma', 'taf', 'tj', 'moda', 'ross', 'fashion', 'old navy', 'marshall', 'vuitton', 'jcpen', 'jean', 'hugo boss', 'gucci', 'gaynor', 'outlet', 'closet', 'c a', 'bols', 'plat', 'aldo conti', 'h&m', 'h & m', 'zara', 'p&b', 'bsk',  'shein', 'joy', 'swatch', 'textil', 'soho', 'lefties', 'zap', 'adidas', 'suburbia', 'nike', 'tienda', 'mall', 'pull', 'shasa', 'telas', 'bersh', 'american eagle'],\n",
    "    'Salud': ['far', 'mvision', 'arceo', 'med', 'lux', 'hos', 'fam', 'dent', 'podol', 'doct', 'dr', 'consult',  'salud', 'odont', 'quiro', 'chopo',  'gnc', 'drog', 'opti', 'hospital', 'clinica', 'benavi', 'ahorro', 'lab', 'derma'],\n",
    "    'Entretenimiento': ['cine', 'foto', 'mubi', 'xbox', 'paramount', 'nintend', 'tinder', 'activision', 'youtube', 'roblox', 'game', 'gandhi', 'unicornio', 'ticket', 'riot', 'cultura', 'hbo', 'sorteo', 'crunchyroll', 'vix', 'noctur', 'dragon', 'boler', 'bolet', 'arena', 'auditorio', 'juguet', 'porrua', 'book', 'teatro', 'arte', 'vide', 'play', 'garena', 'musica', 'mixup', 'juegos', 'spotify', 'prime', 'netflix', 'disney', 'izzi', 'totalplay',  'megacable', 'cel'],\n",
    "    'Tecnologia': ['apple', 'cva', 'steren', 'mac',  'iphone', 'computadora', 'software', 'hardware', 'dell', 'samsung', 'microsoft', 'electronics', 'tvc', 'pc', ],\n",
    "    'Servicios': ['cfe', 'blim', 'cbp',  'deez', 'times', 'godadd', 'ser', 'movist', 'inversio', 'gayosso', 'estafeta', 'envia', 'dhl', 'go dadd', 'canva', 'cable', 'at&t',  'att','seguro', 'univers', 'midjourney', 'adobe', 'tintor', 'zoom', 'storage', 'ayunt', 'agua', 'tel', 'petro', 'gas', 'finanz', 'naturgy', 'gob', 'munici'],\n",
    "    'Viajes': ['airbnb', 'flecha amarilla', 'aero mag', 'magni', 'gran plaza', 'turis', 'inn', 'teso', 'expedia', 'hotel', 'aerom', 'aeropuer', 'premier'],\n",
    "    'Casa': ['home', 'plofer', 'dico', 'imper', 'invern', 'cmx', 'comex', 'plom', 'casa', 'clima', 'ferr', 'refri', 'elect', 'tornill', 'infonavit'],\n",
    "    'Vehiculo': ['auto', 'shell', 'good year', 'gulf', 'icv', 'refac', 'toyota', 'nissan', 'hyund', 'vehi', 'conces', 'wash', 'car', 'moto', 'llant', 'ford', 'audi', ],\n",
    "    'Departamental': ['ekt', 'sol', 'coppel', 'boutique', 'body', 'liver', 'palacio', 'sears', 'bazar'],\n",
    "    'Super': ['cost', 'bae', 'mark', 'circle k', 'mart', 'cityclub', 'retail', 'ctral', 'central', 'abast', 'abrr', 'abts', 'comer', 'merca', 'sam', 'almacen', 'mayore', 'chedra', 'city', 'aur', 'sup', 'jokr', 'city club', 'soriana', 'merco', 'grocery', 'abar', 'wal', 'heb', 'bodeg', 'h-e', 'target'],\n",
    "    'Mascotas': ['vet', 'pet', 'acua', 'animal'],\n",
    "    'Deportes': ['padel', 'dep', 'fitness', 'chivas', 'sultanes', 'deca', 'gym', 'mlb'],\n",
    "    'Educacion': ['uni', 'uvm', 'ccu'],\n",
    "    'Belleza': ['nail', 'beaty', 'perf', 'salon', 'pelu', 'barb', 'beauty', 'makeup', 'make up', 'maquill', 'estetica', 'estética', 'esth',],\n",
    "    'Compras en Linea': ['amazon', 'google', 'shopee', 'shoppe', 'ebay', 'paypal, aliex', 'wish', 'shopify', 'aliexpress'],\n",
    "    'Otros':['facebk', 'fant', 'cash', \"plastic\", 'mateco', 'miniso', 'office', 'tela', 'clip', 'manualidades', 'papel', 'cuero', 'paris', 'nuevo mund', 'regal', 'fantas'],\n",
    "    \n",
    "    # Agregar en Otros Plasticos y Telas y Nombre \n",
    "    # Amazon y Shopee entrar en Compras en Linea\n",
    "    # Modelos Watson x Categorizarloszz\n",
    "}\n",
    "\n",
    "# Se define la funcion label_category que recibe un nombre y lo clasifica en una categoria\n",
    "def label_category(name):\n",
    "    name_lower = name.lower()\n",
    "    for category, keywords in keywords_dict.items():\n",
    "        if any(keyword in name_lower for keyword in keywords):\n",
    "            return category\n",
    "    return 'Miscellaneous'\n",
    "\n",
    "# Se aplica la funcion label_category al dataframe de pandas y se almacena en una nueva columna llamada Category\n",
    "df['Category'] = df['NOM_COM'].apply(label_category)\n",
    "\n",
    "# Se imprime el dataframe de pandas con las nuevas columnas\n",
    "df.to_csv('datos_ofuscados_reprocessed.csv', index=False)\n",
    "\n",
    "# Se imprime el dataframe de pandas con las nuevas columnas y se filtra por las columnas NOM_COM y Category\n",
    "df[['NOM_COM', 'Category']].head()\n",
    "misc_df = df[df['Category'] == 'Miscellaneous'][['NOM_COM', 'Category']]\n",
    "print(misc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.757585e-08</td>\n",
       "      <td>2.842201e-06</td>\n",
       "      <td>1.388061e-06</td>\n",
       "      <td>2.914254e-05</td>\n",
       "      <td>3.289192e-05</td>\n",
       "      <td>1.441785e-04</td>\n",
       "      <td>2.693617e-08</td>\n",
       "      <td>1.853400e-07</td>\n",
       "      <td>3.019990e-04</td>\n",
       "      <td>1.399094e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739600e-03</td>\n",
       "      <td>-4.169905e-02</td>\n",
       "      <td>7.399392e-02</td>\n",
       "      <td>-6.663287e-02</td>\n",
       "      <td>-7.107752e-02</td>\n",
       "      <td>6.753468e-02</td>\n",
       "      <td>-5.568868e-02</td>\n",
       "      <td>-1.241593e-01</td>\n",
       "      <td>5.054401e-02</td>\n",
       "      <td>-5.854644e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.894960e-15</td>\n",
       "      <td>1.965175e-12</td>\n",
       "      <td>1.604455e-12</td>\n",
       "      <td>1.505891e-11</td>\n",
       "      <td>-1.714591e-11</td>\n",
       "      <td>1.140197e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.817386e-11</td>\n",
       "      <td>6.300608e-12</td>\n",
       "      <td>-7.997267e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.677744e-09</td>\n",
       "      <td>1.531114e-08</td>\n",
       "      <td>-1.351526e-09</td>\n",
       "      <td>-2.134065e-08</td>\n",
       "      <td>1.110721e-08</td>\n",
       "      <td>-3.569408e-09</td>\n",
       "      <td>-4.651826e-09</td>\n",
       "      <td>3.341274e-08</td>\n",
       "      <td>-8.683645e-09</td>\n",
       "      <td>2.323511e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.453799e-09</td>\n",
       "      <td>4.783459e-06</td>\n",
       "      <td>3.500764e-07</td>\n",
       "      <td>1.492852e-04</td>\n",
       "      <td>3.086330e-04</td>\n",
       "      <td>6.568670e-01</td>\n",
       "      <td>-1.310599e-08</td>\n",
       "      <td>-1.328133e-06</td>\n",
       "      <td>-4.297617e-04</td>\n",
       "      <td>-3.035684e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.130107e-02</td>\n",
       "      <td>1.013016e-02</td>\n",
       "      <td>-5.936239e-03</td>\n",
       "      <td>2.725989e-03</td>\n",
       "      <td>-1.489133e-03</td>\n",
       "      <td>3.825172e-03</td>\n",
       "      <td>-5.428423e-05</td>\n",
       "      <td>1.746752e-03</td>\n",
       "      <td>4.873551e-03</td>\n",
       "      <td>-3.763031e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.457297e-10</td>\n",
       "      <td>1.027369e-07</td>\n",
       "      <td>1.458984e-08</td>\n",
       "      <td>3.462696e-06</td>\n",
       "      <td>2.291229e-05</td>\n",
       "      <td>3.638431e-05</td>\n",
       "      <td>-4.071871e-08</td>\n",
       "      <td>-6.374429e-08</td>\n",
       "      <td>1.371450e-04</td>\n",
       "      <td>4.872932e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.618011e-02</td>\n",
       "      <td>7.126420e-02</td>\n",
       "      <td>-2.446634e-02</td>\n",
       "      <td>2.057027e-02</td>\n",
       "      <td>1.583287e-02</td>\n",
       "      <td>9.762145e-02</td>\n",
       "      <td>-3.046301e-02</td>\n",
       "      <td>-2.965402e-02</td>\n",
       "      <td>-2.346550e-02</td>\n",
       "      <td>2.094245e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.600702e-08</td>\n",
       "      <td>4.811077e-06</td>\n",
       "      <td>5.623634e-07</td>\n",
       "      <td>1.125104e-04</td>\n",
       "      <td>2.518241e-04</td>\n",
       "      <td>4.901116e-01</td>\n",
       "      <td>-3.115683e-09</td>\n",
       "      <td>-9.429269e-07</td>\n",
       "      <td>-3.558911e-04</td>\n",
       "      <td>9.052033e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.073094e-02</td>\n",
       "      <td>-1.855069e-02</td>\n",
       "      <td>8.101936e-03</td>\n",
       "      <td>-3.929044e-03</td>\n",
       "      <td>2.079973e-03</td>\n",
       "      <td>-1.894688e-03</td>\n",
       "      <td>1.236175e-05</td>\n",
       "      <td>1.027019e-03</td>\n",
       "      <td>5.437843e-03</td>\n",
       "      <td>5.881896e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2             3             4   \\\n",
       "0  4.757585e-08  2.842201e-06  1.388061e-06  2.914254e-05  3.289192e-05   \n",
       "1 -9.894960e-15  1.965175e-12  1.604455e-12  1.505891e-11 -1.714591e-11   \n",
       "2  6.453799e-09  4.783459e-06  3.500764e-07  1.492852e-04  3.086330e-04   \n",
       "3  4.457297e-10  1.027369e-07  1.458984e-08  3.462696e-06  2.291229e-05   \n",
       "4  1.600702e-08  4.811077e-06  5.623634e-07  1.125104e-04  2.518241e-04   \n",
       "\n",
       "             5             6             7             8             9   ...  \\\n",
       "0  1.441785e-04  2.693617e-08  1.853400e-07  3.019990e-04  1.399094e-03  ...   \n",
       "1  1.140197e-09  1.000000e+00 -7.817386e-11  6.300608e-12 -7.997267e-11  ...   \n",
       "2  6.568670e-01 -1.310599e-08 -1.328133e-06 -4.297617e-04 -3.035684e-04  ...   \n",
       "3  3.638431e-05 -4.071871e-08 -6.374429e-08  1.371450e-04  4.872932e-05  ...   \n",
       "4  4.901116e-01 -3.115683e-09 -9.429269e-07 -3.558911e-04  9.052033e-05  ...   \n",
       "\n",
       "             90            91            92            93            94  \\\n",
       "0 -4.739600e-03 -4.169905e-02  7.399392e-02 -6.663287e-02 -7.107752e-02   \n",
       "1 -2.677744e-09  1.531114e-08 -1.351526e-09 -2.134065e-08  1.110721e-08   \n",
       "2 -1.130107e-02  1.013016e-02 -5.936239e-03  2.725989e-03 -1.489133e-03   \n",
       "3  2.618011e-02  7.126420e-02 -2.446634e-02  2.057027e-02  1.583287e-02   \n",
       "4  2.073094e-02 -1.855069e-02  8.101936e-03 -3.929044e-03  2.079973e-03   \n",
       "\n",
       "             95            96            97            98            99  \n",
       "0  6.753468e-02 -5.568868e-02 -1.241593e-01  5.054401e-02 -5.854644e-02  \n",
       "1 -3.569408e-09 -4.651826e-09  3.341274e-08 -8.683645e-09  2.323511e-08  \n",
       "2  3.825172e-03 -5.428423e-05  1.746752e-03  4.873551e-03 -3.763031e-03  \n",
       "3  9.762145e-02 -3.046301e-02 -2.965402e-02 -2.346550e-02  2.094245e-03  \n",
       "4 -1.894688e-03  1.236175e-05  1.027019e-03  5.437843e-03  5.881896e-03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa la libreria sklearn, TruncatedSVD y TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Se crea el vectorizer \n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Se aplica el vectorizer al dataframe de pandas y se almacena en una nueva columna llamada NOM_COM_clean_advanced\n",
    "X_tfidf = vectorizer.fit_transform(df['NOM_COM_clean_advanced'])\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X_tfidf)\n",
    "\n",
    "# Se imprime el dataframe de pandas con las nuevas columnas\n",
    "reduced_df = pd.DataFrame(X_reduced)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa la libreria sklearn, MinMaxScaler y train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Se crea el scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Se escala el dataframe de pandas\n",
    "X_scaled = scaler.fit_transform(X_reduced)\n",
    "\n",
    "# Se imprime el dataframe de pandas con las nuevas columnas\n",
    "y = df['Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  11    0    0    0    0    0    0    0    0    1    0    1    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0  115    5    0    0    0    0    0    0    1    0    0    0    0\n",
      "     1    0    0    0    0]\n",
      " [   0    2 1360    0    0    0    0    2    0   55    1    1    2    5\n",
      "     5    0    0    1    0]\n",
      " [   0    0    1   60    0    0    0    0    0    1    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0   85    0    0    0    1    1    0    0    0    0\n",
      "     1    0    0    0    0]\n",
      " [   1    0    0    0    0    5    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0   13    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    5    0    0    0    0  274    0    6    1    1    0    2\n",
      "     3    0    0    0    1]\n",
      " [   0    0    0    0    0    0    0    0    1    1    1    0    0    1\n",
      "     0    0    0    0    0]\n",
      " [   0    0   36    0    0    1    0    0    0  403    0    4    0    6\n",
      "     2    0    1    3    0]\n",
      " [   0    0    4    0    0    0    0    0    0    3   50    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    8    0    0    0    0    0    0   11    1   82    0    2\n",
      "     1    0    2    0    0]\n",
      " [   0    0   14    0    0    0    1    0    1   16    4    0  307    1\n",
      "     2    0    0    0    0]\n",
      " [   0    0    7    0    0    0    0    0    0    9    0    0    0  561\n",
      "     2    0    0    0    0]\n",
      " [   0    0    6    0    0    0    0    1    0    6    0    0    1    0\n",
      "   532    0    1    0    1]\n",
      " [   0    0    0    0    1    0    0    0    0    1    0    0    0    0\n",
      "     0  109    0    0    0]\n",
      " [   0    0    5    0    0    0    0    0    0    9    0    0    0    0\n",
      "     1    0  896    0    0]\n",
      " [   0    0    5    0    0    0    0    0    0   11    1    0    0    1\n",
      "     0    0    0   55    0]\n",
      " [   0    0    3    0    0    0    0    0    0    3    0    0    0    0\n",
      "     0    0    0    0   19]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9409298780487805,\n",
       " 0.9416209763138333,\n",
       " 0.9444625421249909,\n",
       " 0.9409298780487805)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa la libreria sklearn, RandomForestClassifier, accuracy_score, f1_score, precision_score y recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Se crea el clasificador RandomForestClassifier y se entrena con los datos de entrenamiento\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Se predicen los datos de prueba\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_f1 = f1_score(y_test, rf_y_pred, average='weighted')\n",
    "rf_precision = precision_score(y_test, rf_y_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_y_pred, average='weighted')\n",
    "\n",
    "\n",
    "rf_accuracy, rf_f1, rf_precision, rf_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_dataset_with_predictions.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importan los datos de prueba\n",
    "test_df = pd.read_csv(\"datos_test.csv\")\n",
    "\n",
    "# Se aplica la funcion preprocess_text al dataframe de pandas y se almacena en una nueva columna llamada NOM_COM_clean_advanced\n",
    "test_df['NOM_COM_clean_advanced'] = test_df['NOM_COM'].apply(preprocess_text_advanced)\n",
    "X_test_tfidf = vectorizer.transform(test_df['NOM_COM_clean_advanced'])\n",
    "X_test_reduced = svd.transform(X_test_tfidf)\n",
    "X_test_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "# Se predicen los datos de prueba\n",
    "test_df['Predicted_Category'] = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Se imprime el dataframe de pandas con las nuevas columnas\n",
    "test_dataset_with_predictions_path = 'test_dataset_with_predictions.csv'\n",
    "test_df.to_csv(test_dataset_with_predictions_path, index=False)\n",
    "test_dataset_with_predictions_path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
